# -*- coding: utf-8 -*-
"""Bat_Optimaization

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/manan-arya/Major_Project/blob/Additional_Work/Bat_Optimaization.ipynb
"""

import pandas as pd
import numpy as np

! pip install pyswarms
import pyswarms as ps

url = "https://raw.githubusercontent.com/manan-arya/Major_Project/Additional_Work/after_ga.csv"
data = pd.read_csv(url)

data

#  DATA SELECTOR

x_train = data.iloc[0:100,1:data.shape[1]-1].values
x_test = data.iloc[101:150,1:data.shape[1]-1].values

y_train = data.iloc[0:100,data.shape[1]-1].values
y_test = data.iloc[101:150,data.shape[1]-1].values

y_train = y_train.ravel()
y_test = y_test.ravel()

from sklearn.preprocessing import StandardScaler

sc_x = StandardScaler()
sc_y = StandardScaler()
x_tr = sc_x.fit_transform(x_train)
x_te = sc_x.fit_transform(x_test)
y_tr = sc_y.fit_transform(y_train.reshape(-1,1)).ravel()
y_te = sc_y.fit_transform(y_test.reshape(-1,1)).ravel()

x_tr.shape

y_tr.shape

"""Using Libraly"""

import numpy as np
import random
from itertools import combinations as cb
import math
from copy import deepcopy as dc
from tqdm import tqdm
from sklearn import svm  
from sklearn import model_selection as ms

"""Evaluate Function """
class Evaluate:
    def __init__(self):
        None
    def evaluate(self,gen):
        None
    def check_dimentions(self,dim):
        None

"""Common Function"""
def random_search(n,dim):
    """
    create genes list
    input:{ n: Number of population, default=20
            dim: Number of dimension
    }
    output:{genes_list → [[0,0,0,1,1,0,1,...]...n]
    }
    """
    gens=[[0 for g in range(dim)] for _ in range(n)]
    for i,gen in enumerate(gens) :
        r=random.randint(1,dim)
        for _r in range(r):
            gen[_r]=1
        random.shuffle(gen)
    return gens

"""BBA"""
def BBA(Eval_Func,n=20,m_i=200,dim=None,minf=0,prog=False,qmin=0,qmax=2,loud_A=0.25,r=0.4):
    """
    input:{ Eval_Func: Evaluate_Function, type is class
            n: Number of population, default=20
            m_i: Number of max iteration, default=300
            minf: minimazation flag, default=0, 0=maximization, 1=minimazation
            dim: Number of feature, default=None
            prog: Do you want to use a progress bar?, default=False
            qmin: frequency minimum to step
            qmax: frequency maximum to step
            loud_A: value of Loudness, default=0.25
            r: Pulse rate, default=0.4, Probability to relocate near the best position
            }
    output:{Best value: type float 0.967
            Best position: type list(int) [1,0,0,1,.....]
            Nunber of 1s in best position: type int [0,1,1,0,1] → 3
            }
    """
    estimate=Eval_Func().evaluate
    if dim==None:
        dim=Eval_Func().check_dimentions(dim)
    #flag=dr
    #qmin=0
    #qmax=2
    #loud_A=0.25
    #r=0.1
    #n_iter=0
    gens_dic={tuple([0]*dim):float("-inf") if minf == 0 else float("inf")}
    q=[0 for i in range(n)]
    v=[[0 for d in range(dim)] for i in range(n)]
    #cgc=[0 for i in range(max_iter)]
    fit=[float("-inf") if minf == 0 else float("inf") for i in range(n)]
    #dr=False
    gens=random_search(n,dim)#[[random.choice([0,1]) for d in range(dim)] for i in range(n)]

    for i in range(n):
        if  tuple(gens[i]) in gens_dic:
            fit[i]=gens_dic[tuple(gens[i])]
        else:
            fit[i]=estimate(gens[i])
            gens_dic[tuple(gens[i])]=fit[i]

    if minf==0:
        maxf=max(fit)
        best_v=maxf
        best_s=gens[fit.index(max(fit))]
    elif minf==1:
        minf=min(fit)
        best_v=minf
        best_s=gens[fit.index(min(fit))]


    if prog:
        miter=tqdm(range(m_i))
    else:
        miter=range(m_i)

    for it in miter:
        #cgc[i]=maxf
        for i in range(n):
            for j in range(dim):
                q[i]=qmin+(qmin-qmax)*random.random()
                v[i][j]=v[i][j]+(gens[i][j]-best_s[j])*q[i]

                vstf=abs((2/math.pi)*math.atan((math.pi/2)*v[i][j]))

                if random.random()<vstf:
                    gens[i][j]= 0 if gens[i][j]==1 else 1
                else:
                    pass

                if random.random()>r:
                    gens[i][j]=best_s[j]

            if  tuple(gens[i]) in gens_dic:
                fnew=gens_dic[tuple(gens[i])]
            else:
                fnew=estimate(gens[i])
                gens_dic[tuple(gens[i])]=fnew

            if fnew >= fit[i] and random.random() < loud_A if minf==0 else fnew <= fit[i] and random.random() < loud_A:#max?
                gens[i]=gens[i]
                fit[i]=fnew

            if fnew>best_v if minf==0 else fnew<best_v:
                best_s=dc(gens[i])
                best_v=dc(fnew)

    return best_v,best_s,best_s.count(1)

class Evaluate:
    def __init__(self):
        self.train_label = y_tr
        self.train_data = x_tr
        self.test_label = y_te
        self.test_data = x_te
        self.K = 4
    def evaluate(self,gen):
        mask=np.array(gen) > 0
        al_data=np.array([al[mask] for al in self.train_data])
        al_test_data=np.array([al[mask] for al in self.test_data])
        kf = ms.KFold(n_splits=self.K)
        s = 0
        for tr_ix,te_ix in kf.split(al_data):
          clf = svm.SVR()
          clf = clf.fit(al_data[tr_ix],self.train_label[tr_ix])
          s+=clf.score(al_data[te_ix],self.train_label[te_ix])
        s/=self.K
        return s   #np.count_nonzero(self.test_l==res)/len(self.test_l)
    def check_dimentions(self,dim):
        if dim==None:
            return len(self.train_d[0])
        else:
            return dim

def test_score(gen,tr_x,tr_y,te_x,te_y):
    clf = svm.SVR()
    mask=np.array(gen) == 1
    al_data=np.array(x_tr[:,mask])
    al_test_data=np.array(x_te[:,mask])
    return np.mean([SVR.fit(al_data,y_tr).score(al_test_data,y_te) for i in range(4)])

Bs,Bg,Bl=BBA(Eval_Func=Evaluate,n=len(x_tr[0:]),m_i=200, dim = len(x_tr[0]) ,minf = 0 )

Bs

Bl

BG = np.asarray(Bg)

BG

