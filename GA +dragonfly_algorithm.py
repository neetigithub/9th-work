# -*- coding: utf-8 -*-
"""Dragonfly_Algorithm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/manan-arya/Major_Project/blob/Additional_Work/Dragonfly_Algorithm.ipynb
"""

import pandas as pd
import numpy as np

! pip install pyswarms
import pyswarms as ps

url = "https://raw.githubusercontent.com/manan-arya/Major_Project/Additional_Work/after_ga.csv"
data = pd.read_csv(url)

data

#  DATA SELECTOR

x_train = data.iloc[0:100,1:data.shape[1]-1].values
x_test = data.iloc[101:200,1:data.shape[1]-1].values

y_train = data.iloc[0:100,data.shape[1]-1].values
y_test = data.iloc[101:200,data.shape[1]-1].values

y_train = y_train.ravel()
y_test = y_test.ravel()

from sklearn.preprocessing import StandardScaler

sc_x = StandardScaler()
sc_y = StandardScaler()
x_tr = sc_x.fit_transform(x_train)
x_te = sc_x.fit_transform(x_test)
y_tr = sc_y.fit_transform(y_train.reshape(-1,1)).ravel()
y_te = sc_y.fit_transform(y_test.reshape(-1,1)).ravel()

x_tr.shape

y_tr.shape

"""Using Libraly"""

import numpy as np
import random
from itertools import combinations as cb
import math
from copy import deepcopy as dc
from tqdm import tqdm
from sklearn import svm  
from sklearn import model_selection as ms

"""Evaluate Function """
class Evaluate:
    def __init__(self):
        None
    def evaluate(self,gen):
        None
    def check_dimentions(self,dim):
        None

"""Common Function"""
def random_search(n,dim):
    """
    create genes list
    input:{ n: Number of population, default=20
            dim: Number of dimension
    }
    output:{genes_list → [[0,0,0,1,1,0,1,...]...n]
    }
    """
    gens=[[0 for g in range(dim)] for _ in range(n)]
    for i,gen in enumerate(gens) :
        r=random.randint(1,dim)
        for _r in range(r):
            gen[_r]=1
        random.shuffle(gen)
    return gens

"""BDFA"""
def BDFA(Eval_Func,n=20,m_i=200,dim=None,minf=0,prog=False):
    """
    input:{ Eval_Func: Evaluate_Function, type is class
            n: Number of population, default=20
            m_i: Number of max iteration, default=300
            minf: minimazation flag, default=0, 0=maximization, 1=minimazation
            dim: Number of feature, default=None
            prog: Do you want to use a progress bar?, default=False
            }
    output:{Best value: type float 0.967
            Best position: type list(int) [1,0,0,1,.....]
            Nunber of 1s in best position: type int [0,1,1,0,1] → 3
            }
    """
    estimate=Eval_Func().evaluate
    if dim==None:
        dim=Eval_Func().check_dimentions(dim)
    maxiter=m_i#500
    #flag=dr#True
    best_v=float("-inf") if minf == 0 else float("inf")
    best_p=[0]*dim
    gens_dict={tuple([0]*dim):float("-inf") if minf == 0 else float("inf")}

    enemy_fit=float("-inf") if minf == 0 else float("inf")
    enemy_pos=[0 for _ in range(dim)]
    food_fit=float("-inf") if minf == 0 else float("inf")
    food_pos=[0 for _ in range(dim)]

    fit=[0 for _ in range(n)]
    genes=random_search(n,dim)
    genesX=random_search(n,dim)

    if prog:
        miter=tqdm(range(m_i))
    else:
        miter=range(m_i)
    for it in miter:
        w=0.9 - it * ((0.9-0.4) / maxiter)
        mc=0.1- it * ((0.1-0) / (maxiter/2))
        if mc < 0:
            mc=0
        s=2 * random.random() * mc
        a=2 * random.random() * mc
        c=2 * random.random() * mc
        f=2 * random.random()
        e=mc
        if it > (3*maxiter/3):
            e=0

        for i in range(n):
            if tuple(genes[i]) in gens_dict:
                fit[i]=gens_dict[tuple(genes[i])]
            else:
                fit[i]=estimate(genes[i])
                gens_dict[tuple(genes[i])]=dc(fit[i])
            if fit[i] > food_fit if minf==0 else fit[i] < food_fit:
                food_fit=dc(fit[i])
                food_pos=dc(genes[i])

            if fit[i] > enemy_fit if minf==0 else fit[i] < enemy_fit:
                enemy_fit=dc(fit[i])
                enemy_pos=dc(genes[i])

        for i in range(n):
            ind=-1
            nn=-1
            ndx=[[0 for _d in range(dim)] for _ in range(n)]
            nx=[[0 for _d in range(dim)] for _ in range(n)]

            for j in range(n):
                if i==j:
                    pass
                else:
                    ind+=1
                    nn+=1
                    ndx[ind]=dc(genesX[j])
                    nx[ind]=dc(genes[j])

            S=[0 for _ in range(dim)]
            for k in range(nn):
                S=[_s+(_x-_y) for _s,(_x,_y) in zip(S,zip(ndx[k],genes[i]))] #s+(nx[k]-x[i])
            S=S

            A=[sum([_[_d] for _ in ndx])/nn for _d in range(dim)]#[sum(_)/nn if _ != 0 else 0 for _ in ndx]
            #[_-g for _,g in zip([sum([_[_d] for _ in nx])/nn for _d in range(dim)],genes[i])]
            C=[_-g for _,g in zip([sum([_[_d] for _ in nx])/nn for _d in range(dim)],genes[i])]#[sum(_)/nn-g if _ != 0 else 0 for _,g in zip(nx,genes[i])]

            F=[fp-g for fp,g in zip(food_pos,genes[i])]
            E=[ep+g for  ep,g in zip(enemy_pos,genes[i])]

            for j in range(dim):
                genesX[i][j]=s*S[j]+a*A[j]+c*C[j]+ f *F[j]+e*E[j]+w*genesX[i][j]

                if genesX[i][j] > 6:
                    genesX[i][j]=6
                if genesX[i][j] < -6:
                    genesX[i][j]=-6
                T = abs(genesX[i][j] / math.sqrt((1+genesX[i][j]**2)))
                if random.random()<T:
                    genes[i][j]=1 if genes[i][j] == 0 else 0
    best_p=food_pos
    best_v=food_fit

    return best_v,best_p,best_p.count(1)



class Evaluate:
    def __init__(self):
        self.train_label = y_tr
        self.t-rain_data = x_tr
        self.test_label = y_te
        self.test_data = x_te
        self.K = 4
    def evaluate(self,gen):
        mask=np.array(gen) > 0
        al_data=np.array([al[mask] for al in self.train_data])
        al_test_data=np.array([al[mask] for al in self.test_data])
        kf = ms.KFold(n_splits=self.K)
        s = 0
        for tr_ix,te_ix in kf.split(al_data):
          clf = svm.SVR()
          clf = clf.fit(al_data[tr_ix],self.train_label[tr_ix])
          s+=clf.score(al_data[te_ix],self.train_label[te_ix])
        s/=self.K
        return s   #np.count_nonzero(self.test_l==res)/len(self.test_l)
    def check_dimentions(self,dim):
        if dim==None:
            return len(self.train_d[0])
        else:
            return dim

def test_score(gen,tr_x,tr_y,te_x,te_y):
    clf = svm.SVR()
    mask=np.array(gen) == 1
    al_data=np.array(x_tr[:,mask])
    al_test_data=np.array(x_te[:,mask])
    return np.mean([SVR.fit(al_data,y_tr).score(al_test_data,y_te) for i in range(4)])

Cs,Cg,Cl=BDFA(Eval_Func=Evaluate,n=len(x_tr[0:]),m_i=200, dim = len(x_tr[0]), minf = 0)

Cs # Accuracy

Cl # no. of features

CG = np.asarray(Cg)

CG.reshape(1,700) # Feature array

